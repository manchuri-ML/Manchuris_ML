{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7wApo_1IplZ7"
      },
      "outputs": [],
      "source": [
        "## https://github.com/OPENAIRINTERFACE/openairinterface5g\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "def clone_repo(git_url, repo_name=\"codebase\"):\n",
        "    if os.path.exists(repo_name):\n",
        "        subprocess.run([\"rm\", \"-rf\", repo_name])\n",
        "    subprocess.run([\"git\", \"clone\", git_url, repo_name])\n",
        "    return repo_name\n",
        "\n",
        "# Example\n",
        "repo_path = clone_repo(\"https://github.com/OPENAIRINTERFACE/openairinterface5g\", \"openairinterface5g\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEqPkp3CrI7a",
        "outputId": "a12f4ce0-a9ca-46a8-d25f-ba77fa7f45e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: pgvector in /usr/local/lib/python3.11/dist-packages (0.4.1)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.11/dist-packages (2.9.10)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community pgvector psycopg2-binary transformers sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IjZN848urUB7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores.pgvector import PGVector\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "# 2. Load + Chunk Code\n",
        "def load_and_chunk_code(repo_path):\n",
        "    chunks = []\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    for root, _, files in os.walk(repo_path):\n",
        "        for file in files:\n",
        "            if file.endswith((\".c\", \".h\", \".cpp\", \".py\", \".java\")):\n",
        "                file_path = os.path.join(root, file)\n",
        "                with open(file_path, \"r\", errors=\"ignore\") as f:\n",
        "                    content = f.read()\n",
        "                    for chunk in splitter.split_text(content):\n",
        "                        chunks.append(Document(page_content=chunk, metadata={\"source\": file_path}))\n",
        "    return chunks\n",
        "\n",
        "# 3. Store in AWS RDS\n",
        "def store_in_pgvector(docs, aws_connection_string):\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    PGVector.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embedding_model,\n",
        "        connection_string=aws_connection_string,\n",
        "        collection_name=\"enterprise_code\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeCNEpufrikX"
      },
      "outputs": [],
      "source": [
        "# Commented AWS RDB for security purpose\n",
        "AWS_DB_URI = \" xxxxxxxxxxxxxxxxxx\"  \n",
        "chunks = load_and_chunk_code(repo_path)\n",
        "#store_in_pgvector(chunks, AWS_DB_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIbYc0aEs5xV",
        "outputId": "8f8010d7-f467-4fd8-9a78-0df35f70eb5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-b141f533c837>:8: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata. Please note that filtering operators have been changed when using JSONB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create a db migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
            "  vectorstore = PGVector(\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores.pgvector import PGVector\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Connect to your AWS-hosted pgvector\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = PGVector(\n",
        "    embedding_function=embedding_model,\n",
        "    connection_string=AWS_DB_URI,\n",
        "    collection_name=\"enterprise_code\"\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    embedding=embedding_model,  # this is where you use it\n",
        "    search_kwargs={\"k\": 5}\n",
        ")\n",
        "\n",
        "# Example Query\n",
        "query = \"Summarize resource scheduling in LTE and implement dynamic spectrum sharing\"\n",
        "docs = retriever.get_relevant_documents(query)\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqJuTg4ZtCuE",
        "outputId": "5bc71327-6c27-4471-fb5d-22256508ef39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at Salesforce/codegen-350M-mono were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
            "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Here is some L1 layer code:\n",
            "\n",
            "// This function assigns pre-available RBS to each UE in specified sub-bands before scheduling is done\n",
            "void\n",
            "dlsch_scheduler_pre_processor(module_id_t Mod_id,\n",
            "                              int CC_id,\n",
            "                              frame_t frameP,\n",
            "                              sub_frame_t subframeP) {\n",
            "  eNB_MAC_INST *mac = RC.mac[Mod_id];\n",
            "  UE_info_t *UE_info = &mac->UE_info;\n",
            "  const int N_RBG = to_rbg(mac->common_channels[CC_id].mib->message.dl_Bandwidth);\n",
            "  const int RBGsize = get_min_rb_unit(Mod_id, CC_id);\n",
            "\n",
            "  store_dlsch_buffer(Mod_id, CC_id, frameP, subframeP);\n",
            "\n",
            "  UE_list_t UE_to_sched;\n",
            "  for (int i = 0; i < MAX_MOBILES_PER_ENB; ++i)\n",
            "    UE_to_sched.next[i] = -1;\n",
            "  int *cur = &UE_to_sched.head;\n",
            "\n",
            "  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {\n",
            "    UE_sched_ctrl_t *ue_sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];\n",
            "    const UE_TEMPLATE *ue_template = &UE_info->UE_template[CC_id][UE_id];\n",
            "\n",
            "/// (only in-band mode), indicate the resource block overlap the SRS configuration of LTE\n",
            "  uint8_t                 N_srs;\n",
            "  ///\n",
            "  uint8_t                 scrambling_re_intialization_batch_index;\n",
            "  /// number of cell specific TX antenna ports assumed by the UE\n",
            "  uint8_t                 nrs_antenna_ports;\n",
            "  ///\n",
            "  uint16_t                scrambling_sequence_intialization;\n",
            "  ///\n",
            "  uint16_t                sf_index;\n",
            "  /// Determined the ACK/NACK delay and the subcarrier allocation TS 36.213 Table 16.4.2\n",
            "  uint8_t                 HARQ_ACK_resource;\n",
            "\n",
            "// Scheduling Request Config\n",
            "  SCHEDULING_REQUEST_CONFIG scheduling_request_config[NUMBER_OF_UE_MAX];\n",
            "\n",
            "  // Transmission mode per UE\n",
            "  uint8_t transmission_mode[NUMBER_OF_UE_MAX];\n",
            "\n",
            "  /// cba_last successful reception for each group, used for collision detection\n",
            "  uint8_t cba_last_reception[4];\n",
            "\n",
            "  // Pointers for active physicalConfigDedicated to be applied in current subframe\n",
            "  struct LTE_PhysicalConfigDedicated *physicalConfigDedicated[NUMBER_OF_UE_MAX];\n",
            "\n",
            "\n",
            "  uint32_t rb_mask_ul[4];\n",
            "\n",
            "  /// Information regarding TM5\n",
            "  MU_MIMO_mode mu_mimo_mode[NUMBER_OF_\n",
            "\n",
            "Develop modular functions for dynamic spectrum sharing feature in LTE with 70:30 split. \n",
            "Please see the corresponding L2 bandwidth control function, in this section, in the\n",
            "lstbm_csc.cu file, to get information about the L2 bandwidth of the Mobile Unit.\n",
            "\n",
            "-----------------------------------------------------------------------------\n",
            "\n",
            "// (in-band mode)\n",
            "// To make sure the RTT is not overload\n",
            "for (int UE_id = UE_info->head; UE_id >= 0; UE_id = UE_info->head)\n",
            "{\n",
            "   scrambling_sequence_intialization = ((ue_scrambling_sequence_intialization * N_srs) + UE_scrambling_sequence_intialization(UE_id));\n",
            "\n",
            "   // Find out the highest bandwidth allocation TS\n",
            "   uint16_t    BW_alloc_ts[N_srs];\n",
            "   const uint16_t  BW_alloc_interval[N_srs];\n",
            "\n",
            "   // Retrieve corresponding bandwidth allocation and their interval\n",
            "   BW_alloc_interval[0+UE_scrambling_sequence_intialization] =UE_scrambling_sequence_intialization(UE_id);\n",
            "   BW_alloc_interval[UE_scrambling_sequence_intialization] = to_uint16(BW_alloc_interval[UE_scrambling_sequence_intialization]/2);\n",
            "   BW_alloc_interval[UE_scrambling_sequence_intialization+1] =to_uint16(BW_alloc_interval[SBG_MACMASS]*BANDWIDTH/MAXIMUM_BANDWIDTH);\n",
            "   \n",
            "\n",
            "   // Retrieve UE's current schedule and transmission interval\n",
            "   UE_sched_ctrl_t      UE_info->UE_sched_ctrl[UE_scrambling_sequence_intialization];\n",
            "\n",
            "   // Retrieve UE's current schedule and transmission interval\n",
            "   uint32_t          ue_sched_ctr_list[NB_UE_ID+1];\n",
            "\n",
            "// Get resource block allocation\n",
            "for (int eNB_MAC_PORT_offset = 1;   eNB_MAC_PORT_offset < NUMBER_OF_RB_SUB_PARA; eNB_MAC_PORT_offset++) {\n",
            "    const uint8_t *MAC = rb_mask_ul[eNB\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "model_id = \"Salesforce/codegen-350M-mono\"  # Replace with CodeLlama, DeepSeek etc. if needed\n",
        "os.environ[\"HUGGINGFACE_TOKEN\"] = \"xxxxxxxxxxxx\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token = os.environ[\"HUGGINGFACE_TOKEN\"])\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, token=os.environ[\"HUGGINGFACE_TOKEN\"])\n",
        "codegen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Here is some L1 layer code:\n",
        "\n",
        "{context[:2048]}\n",
        "\n",
        "Develop modular functions for dynamic spectrum sharing feature in LTE with 70:30 split.\n",
        "\"\"\"\n",
        "\n",
        "result = codegen(prompt)\n",
        "print(result[0]['generated_text'])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
