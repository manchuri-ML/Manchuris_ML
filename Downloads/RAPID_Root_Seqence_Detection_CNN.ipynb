{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rczVNWvodqt1",
        "outputId": "d7120e26-cde0-44c1-ead4-8ba87ad18ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "Ut5LDf4HfPAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks')\n",
        "#!ls\n",
        "print(\"Loading Data\")\n",
        "labels = pd.read_csv('Labels.csv', header=None)\n",
        "Training = pd.read_csv('Training_Data.csv', header=None)\n",
        "# Stack real and imaginary components in the desired format\n",
        "num_samples = Training.shape[0]  # Get the number of samples\n",
        "num_features = Training.shape[1]  # Get the number of original features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RFRWKdKeUMm",
        "outputId": "a8e5585c-5f9f-425d-f929-17af6b165c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Dependencies\")\n",
        "from __future__ import division, print_function, absolute_import\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        " #1. Load Data\n",
        "# 2. Preprocess Data\n",
        "Training_complex = Training.applymap(lambda x: complex(str(x).replace('i', 'j')))\n",
        "real_df = Training_complex.applymap(lambda x: x.real)\n",
        "imag_df = Training_complex.applymap(lambda x: x.imag)\n",
        "Stacked_Training_input = np.zeros((4096, 839, 2, 1), dtype=np.float32)\n",
        "\n",
        "#Stacked_Training_input = pd.concat([real_df, imag_df], axis=1)  # Stack in columns first\n",
        "#Stacked_Training_input = Stacked_Training_input.values.reshape(num_samples, num_features, 2)  # Reshape to (samples, features, 2)\n",
        "#Stacked_Training_input = Stacked_Training_input.transpose(0, 2, 1)  # Transpose to (samples, 2, features)\n",
        "#Stacked_Training_input = Stacked_Training_input.reshape(num_samples, num_features * 2, 1, 1)  # Reshape to final format\n",
        "Stacked_Training_input[:, :, 0, 0] = real_df.values  # Real component in channel 0\n",
        "Stacked_Training_input[:, :, 1, 0] = imag_df.values  # Real component in channel 0\n",
        "\n",
        "labels = labels.T  # Transpose to get (4096, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay1_uInFhAkj",
        "outputId": "b545d271-4e52-49bb-dfcd-2e1162ede0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Dependencies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-ca041ebf4ae8>:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  Training_complex = Training.applymap(lambda x: complex(str(x).replace('i', 'j')))\n",
            "<ipython-input-55-ca041ebf4ae8>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  real_df = Training_complex.applymap(lambda x: x.real)\n",
            "<ipython-input-55-ca041ebf4ae8>:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  imag_df = Training_complex.applymap(lambda x: x.imag)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c83eE08ahNbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb1802f-2a23-49b4-9b28-44272c1ee892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 1s/step - binary_accuracy: 0.9797 - loss: 0.2992\n",
            "Epoch 2/4\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 1s/step - binary_accuracy: 0.9844 - loss: 0.2518\n",
            "Epoch 3/4\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 1s/step - binary_accuracy: 0.9844 - loss: 0.2518\n",
            "Epoch 4/4\n",
            "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - binary_accuracy: 0.9844 - loss: 0.2518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e2cf05a1450>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# 3. Define the Neural Network\n",
        "class ReshapeLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, target_shape, **kwargs):\n",
        "        super(ReshapeLayer, self).__init__(**kwargs)\n",
        "        self.target_shape = target_shape\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.reshape(inputs, self.target_shape)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ReshapeLayer, self).get_config()\n",
        "        config.update({'target_shape': self.target_shape})\n",
        "        return config\n",
        "\n",
        "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
        "    with tf.compat.v1.variable_scope('ConvNet', reuse=reuse):\n",
        "        x = x_dict['images']\n",
        "#        x = tf.expand_dims(tf.expand_dims(x, axis=-1), axis=1)  # Reshape to (None, 1, 839, 2, 1)\n",
        "        x = ReshapeLayer(target_shape=(-1, 1, 839, 2, 1))(x)\n",
        "\n",
        "\n",
        "        # More convolutional layers with increasing filters\n",
        "        conv1 = tf.keras.layers.Conv3D(32, [1, 3, 2], activation='relu', padding='same')(x)\n",
        "        conv1 = tf.keras.layers.MaxPooling3D([1, 2, 1], [1, 2, 1], padding='same')(conv1)\n",
        "        conv2 = tf.keras.layers.Conv3D(64, [1, 3, 2], activation='relu', padding='same')(conv1)\n",
        "        conv2 = tf.keras.layers.MaxPooling3D([1, 2, 1], [1, 2, 1], padding='same')(conv2)\n",
        "        conv3 = tf.keras.layers.Conv3D(128, [1, 3, 2], activation='relu', padding='same')(conv2)  # Added layer\n",
        "        conv3 = tf.keras.layers.MaxPooling3D([1, 2, 1], [1, 2, 1], padding='same')(conv3)  # Added layer\n",
        "\n",
        "        # Flatten and dense layers\n",
        "        fc1 = tf.keras.layers.Flatten()(conv3)\n",
        "        fc1 = tf.keras.layers.Dense(2048, activation='relu')(fc1)  # Increased units, added activation\n",
        "        fc1 = tf.keras.layers.Dropout(rate=dropout)(fc1)\n",
        "        fc2 = tf.keras.layers.Dense(1024, activation='relu')(fc1)  # Added another dense layer\n",
        "        fc2 = tf.keras.layers.Dropout(rate=dropout)(fc2)\n",
        "\n",
        "        # Output layer\n",
        "        out = tf.keras.layers.Dense(n_classes)(fc2)\n",
        "    return out\n",
        "\n",
        "# 4. Create and Compile the Model\n",
        "X_input = tf.keras.Input(shape=(839, 2, 1), dtype=tf.float32)  # Updated input shape\n",
        "learning_rate = 0.001\n",
        "num_steps = 2000\n",
        "batch_size = 10\n",
        "num_classes = 128\n",
        "logits = conv_net({'images': X_input}, num_classes, 0.25, reuse=False, is_training=True)\n",
        "model = tf.keras.Model(inputs=X_input, outputs=logits)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# 5. Train the Model\n",
        "model.fit(Stacked_Training_input, labels,\n",
        "          batch_size=batch_size, epochs=num_steps // (len(Stacked_Training_input) // batch_size),\n",
        "          verbose=1)\n",
        "\n",
        "# 6. Evaluate the Model (Add your evaluation code here)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Stacked_Training_input[0,0,1,:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AklDHhJojWS",
        "outputId": "2257b8c9-d671-4cef-e214-d5da34342b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.]\n"
          ]
        }
      ]
    }
  ]
}